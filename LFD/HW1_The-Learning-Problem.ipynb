{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Learning Problem\n",
    "* What types of Machine Learning, if any, best describe the following three scenarios:\n",
    "\n",
    "    (i) A coin classification system is created for a vending machine. The developers obtain exact coin specifications from the U.S. Mint and derive a statistical model of the size, weight, and denomination, which the vending machine then uses to classify coins.  \n",
    "    (ii) Instead of calling the U.S. Mint to obtain coin information, an algorithm is presented with a large set of labeled coins. The algorithm uses this data to infer decision boundaries which the vending machine then uses to classify its coins.  \n",
    "    (iii) A computer develops a strategy for playing Tic-Tac-Toe by playing repeatedly and adjusting its strategy by penalizing moves that eventually lead to losing.\n",
    "\n",
    "     [a] (i) Supervised Learning, (ii) Unsupervised Learning, (iii) Reinforcement Learning  \n",
    "     [b] (i) Supervised Learning, (ii) Not learning, (iii) Unsupervised Learning  \n",
    "     [c] (i) Not learning, (ii) Reinforcement Learning, (iii) Supervised Learning  \n",
    "     [d] (i) Not learning, (ii) Supervised Learning, (iii) Reinforcement Learning  \n",
    "     [e] (i) Supervised Learning, (ii) Reinforcement Learning, (iii) Unsupervised Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Some helpful definitions (from the following website http://enhancedatascience.com/2017/07/19/machine-learning-explained-supervised-learning-unsupervised-learning-and-reinforcement-learning/)\n",
    "\n",
    "**Supervised Learning**:\n",
    "Supervised learning regroups different techniques which all share the same principles:\n",
    "\n",
    "   * The training dataset contains inputs data (your predictors) and the value you want to predict (which can be numeric or not).\n",
    "    \n",
    "   * The model will use the training data to learn a link between the input and the outputs. Underlying idea is that the training data can be generalized and that the model can be used on new data with some accuracy.\n",
    "\n",
    "Some supervised learning algorithms:\n",
    "\n",
    "   1. Linear and logistic regression\n",
    "\n",
    "   1. Support vector machine\n",
    "\n",
    "   1. Naive Bayes\n",
    "\n",
    "   1. Neural network\n",
    "\n",
    "   1. Gradient boosting\n",
    "\n",
    "   1. Classification trees and random forest\n",
    "   \n",
    "**Unsupervised Learning**\n",
    "On the other hand, unsupervised learning does not use output data (at least output data that are different from the input). Unsupervised algorithms can be split into different categories:\n",
    "\n",
    "   * Clustering algorithm, such as K-means, hierarchical clustering or mixture models. These algorithms try to discriminate and separate the observations in different groups.\n",
    "\n",
    "   * Dimensionality reduction algorithms (which are mostly unsupervised) such as PCA, ICA or autoencoder. These algorithms find the best representation of the data with fewer dimensions.\n",
    "   \n",
    "   * Anomaly detections to find outliers in the data, i.e. observations which do not follow the data set patterns.\n",
    "   \n",
    "Most of the time unsupervised learning algorithms are used to pre-process the data, during the exploratory analysis or to pre-train supervised learning algorithms.\n",
    "\n",
    "**Reinforced Learning**\n",
    "Reinforcement learning algorithms try to find the best ways to earn the greatest reward. Rewards can be winning a game, earning more money or beating other opponents. They present state-of-art results on very human task, for instance, [this paper](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf) from the University of Toronto shows how a computer can beat human in old-school Atari video game.\n",
    "\n",
    "From Wikipedia: Reinforcement Learning\n",
    "Given its and the environment’s states, the agent will choose the action which will maximize its reward or will explore a new possibility. These actions will change the environment’s and the agent states. They will also be interpreted to give a reward to the agent. By performing this loop many times, the agents will improve its behavior.\n",
    "\n",
    "Reinforcement learning already performs wells on ‘small’ dynamic system and is definitely to follow for the years to come.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which of the following problems are best suited for Machine Learning?\n",
    "\n",
    "    (i) Classifying numbers into primes and non-primes.  \n",
    "    (ii) Detecting potential fraud in credit card charges.  \n",
    "    (iii) Determining the time it would take a falling object to hit the ground.  \n",
    "    (iv) Determining the optimal cycle for traffic lights in a busy intersection.\n",
    "\n",
    "     [a] (ii) and (iv)  \n",
    "     [b] (i) and (ii)  \n",
    "     [c] (i), (ii), and (iii)  \n",
    "     [d] (iii)  \n",
    "     [e] (i) and (iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
